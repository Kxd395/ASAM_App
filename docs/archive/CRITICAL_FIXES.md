# üö® CRITICAL FIXES REQUIRED

**Date**: November 8, 2025  
**Status**: **HIGH PRIORITY - APPLY BEFORE PHASE 1**  
**Source**: Executive Security & Legal Review

---

## ‚ö†Ô∏è Executive Verdict

Solid foundation, but **12 high-risk gaps** identified that will cause legal exposure, EMR interoperability failures, and audit deficiencies if not fixed immediately.

**Action Required**: Apply all patches below BEFORE starting Phase 1 implementation.

---

## üî¥ Critical Fixes (Apply This Week)

### 1. Package Naming Leaks Brand Risk ‚ùå BLOCKING

**Problem**: Internal Python package named `asamplan` violates our own "do not use ASAM in code" rule. Will leak into imports, logs, stack traces.

**Fix**: Rename to `sudplan` (Substance Use Disorder Plan) everywhere.

**Impact**: All imports, pyproject.toml, CI, tasks, documentation

**Files to Update**:
- `pyproject.toml`: `name = "sudplan"`
- All imports: `from sudplan` not `from asamplan`
- `RESTRUCTURE_PLAN.md`: Update all paths
- `IMPLEMENTATION_SUMMARY.md`: Update package name
- `.vscode/tasks.json`: Update task commands
- `README.md`: Update references

**Search & Replace**:
```bash
# Find all instances
grep -r "asamplan" . --exclude-dir=node_modules --exclude-dir=.git

# Replace (verify each)
find . -type f \( -name "*.py" -o -name "*.toml" -o -name "*.md" -o -name "*.json" \) \
  -exec sed -i '' 's/asamplan/sudplan/g' {} +
```

---

### 2. Test Data Uses ASAM Level Labels ‚ùå BLOCKING

**Problem**: Tables show "2.1 - IOP", "3.7 - Inpatient" which implies ASAM taxonomy usage. Risky without license.

**Fix**: Use neutral internal codes only. Create private mapping table.

**Changes Required**:

1. **Test Data Table** - Replace:
   - "2.1 - IOP" ‚Üí "IOP"
   - "2.5 - Partial Hospitalization" ‚Üí "PH"
   - "3.1 - Residential" ‚Üí "RES-3"
   - "3.7 - Inpatient Intensive" ‚Üí "INP-MED"
   - "3.7-WM - Pregnant Women" ‚Üí "INP-MED-PW"
   - "0.5 - Early Intervention" ‚Üí "EARLY"
   - "1 - Outpatient" ‚Üí "OP"
   - "OMT - Maintenance" ‚Üí "MAT-MAINT"

2. **Create Private Mapping** (`docs/mappings/levels.md`):
```markdown
# Internal Level Codes (Analyst Reference Only - NOT SHIPPED)

| Internal Code | Description | ASAM Reference (If Licensed) |
|--------------|-------------|------------------------------|
| EARLY | Early Intervention | Level 0.5 |
| OP | Outpatient | Level 1 |
| IOP | Intensive Outpatient | Level 2.1 |
| PH | Partial Hospitalization | Level 2.5 |
| RES-3 | Residential | Level 3.1 |
| INP-MED | Inpatient Medical | Level 3.7 |
| INP-MED-PW | Inpatient Pregnant Women | Level 3.7-WM |
| MAT-MAINT | Medication Maintenance | OMT |
```

---

### 3. Legal Checker is Easy to Sidestep ‚ùå BLOCKING

**Problem**: Only scans `src/` and simple filename matches. Misses docs, PDFs, sample data.

**Fix**: Enhanced scanner with PDF text extraction and repo-wide coverage.

**New Script** (`scripts/check-legal-compliance.sh`):
```bash
#!/bin/bash
# Enhanced legal compliance checker

set -e

echo "üîç Scanning for ASAM IP violations..."

PROHIBITED_TERMS=(
    "ASAM Criteria"
    "ASAM Dimension"
    "ASAM Level"
    "CONTINUUM"
    "CO-Triage"
    "CO Triage"
)

violations=0

# Scan code directories
echo "üìÇ Scanning source code..."
for term in "${PROHIBITED_TERMS[@]}"; do
    if grep -r "$term" src/ --exclude-dir=__pycache__ 2>/dev/null; then
        echo "‚ùå Found prohibited term in code: '$term'"
        violations=$((violations+1))
    fi
done

# Scan documentation
echo "üìÑ Scanning documentation..."
DOC_DIRS=("docs" "README.md" "IMPLEMENTATION_SUMMARY.md" "RESTRUCTURE_PLAN.md")
for d in "${DOC_DIRS[@]}"; do
    if [ -e "$d" ]; then
        for term in "${PROHIBITED_TERMS[@]}"; do
            if grep -r "$term" "$d" --exclude="LEGAL_NOTICE.md" --exclude="DESIGN_CLARIFICATION.md" 2>/dev/null; then
                echo "‚ö†Ô∏è  Found term in docs (review context): '$term' in $d"
            fi
        done
    fi
done

# Scan PDFs with text extraction
echo "üìë Scanning PDF files..."
if command -v pdftotext >/dev/null 2>&1; then
    while IFS= read -r -d '' pdf; do
        txt="$(mktemp)"
        if pdftotext "$pdf" "$txt" 2>/dev/null; then
            for term in "${PROHIBITED_TERMS[@]}"; do
                if grep -qi "$term" "$txt"; then
                    echo "‚ùå PDF contains prohibited term: $pdf (term: $term)"
                    violations=$((violations+1))
                fi
            done
        fi
        rm -f "$txt"
    done < <(find assets -type f -name "*.pdf" -print0 2>/dev/null)
else
    echo "‚ö†Ô∏è  pdftotext not found - install poppler-utils for PDF scanning"
fi

# Check for MRN/FIN in filenames
echo "üîí Checking for PHI in filenames..."
if find out/ data/ -type f 2>/dev/null | grep -E "(MRN|FIN|mrn|fin)" | grep -v "test_patients.json"; then
    echo "‚ùå Found MRN/FIN in filenames (PHI violation)"
    violations=$((violations+1))
fi

# Check for official ASAM templates
echo "üìã Checking for ASAM templates..."
if find assets/ -type f -name "*ASAM*.pdf" 2>/dev/null | grep -v PLACEHOLDER; then
    echo "‚ùå Found ASAM PDF template in assets/"
    violations=$((violations+1))
fi

# Summary
echo ""
if [ $violations -eq 0 ]; then
    echo "‚úÖ No critical ASAM IP violations detected"
    exit 0
else
    echo "‚ùå $violations violation(s) detected"
    echo "Review findings above and remove prohibited content"
    exit 1
fi
```

**GitHub Actions Integration** (`.github/workflows/legal-check.yml`):
```yaml
name: Legal Compliance Check

on:
  pull_request:
  push:
    branches: [main, develop]

jobs:
  legal-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install poppler-utils
        run: sudo apt-get install -y poppler-utils
      - name: Run Legal Compliance Checker
        run: |
          chmod +x scripts/check-legal-compliance.sh
          ./scripts/check-legal-compliance.sh
```

**Make Required**: Repository settings ‚Üí Branches ‚Üí Add rule ‚Üí Require "Legal Compliance Check" to pass

---

### 4. PDF Compliance Not Proven ‚ùå BLOCKING

**Problem**: AcroForm fill and stamp are POC-grade. No PDF/A, font embedding, flattening, or integrity signature.

**Fix**: Production-grade PDF pipeline with validation.

**Requirements**:
1. Flatten AcroForm after fill
2. Embed all fonts
3. Optional: CMS signature with enterprise certificate
4. CI preflight validation

**Updated PDF Service**:
```python
# src/sudplan/services/pdf_service.py
import subprocess
from pathlib import Path

class PDFService:
    async def export_plan(
        self,
        plan: Plan,
        signature_image: bytes,
        output_path: Path,
        flatten: bool = True,
        embed_fonts: bool = True
    ) -> Path:
        """Export plan to production-grade PDF"""
        
        # Step 1: Fill AcroForm (existing Swift CLI)
        temp_filled = output_path.with_suffix('.temp.pdf')
        await self._call_swift_cli(plan, signature_image, temp_filled)
        
        # Step 2: Flatten annotations
        if flatten:
            await self._flatten_pdf(temp_filled, output_path)
            temp_filled.unlink()
        else:
            temp_filled.rename(output_path)
        
        # Step 3: Validate output
        await self._validate_pdf(output_path)
        
        return output_path
    
    async def _flatten_pdf(self, input_pdf: Path, output_pdf: Path):
        """Flatten PDF using pdftk or similar"""
        subprocess.run(
            ['pdftk', str(input_pdf), 'output', str(output_pdf), 'flatten'],
            check=True
        )
    
    async def _validate_pdf(self, pdf_path: Path):
        """Validate PDF structure"""
        # Check file size (EMR limits: 5-10MB)
        size_mb = pdf_path.stat().st_size / (1024 * 1024)
        if size_mb > 10:
            raise ValueError(f"PDF too large: {size_mb:.1f}MB (max 10MB)")
        
        # TODO: Add PDF/A validation if required
        # TODO: Add font embedding check
```

**CI Preflight** (`.github/workflows/pdf-validation.yml`):
```yaml
name: PDF Validation

on: [pull_request]

jobs:
  validate-pdfs:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install PDF tools
        run: sudo apt-get install -y pdftk qpdf
      - name: Validate test PDFs
        run: |
          # Run PDF generation tests
          pytest tests/integration/test_pdf_export.py
          # Validate outputs
          for pdf in out/test_*.pdf; do
            qpdf --check "$pdf"
          done
```

---

### 5. Signature Policy Needs One More Guard ‚úÖ ENHANCEMENT

**Problem**: Good ephemeral handling, but missing re-signature on data changes and device ID tracking.

**Fix**: Add mandatory re-signature policy and enhanced metadata.

**Updated Signature Model**:
```python
# src/sudplan/models/signature.py
from pydantic import BaseModel
from datetime import datetime

class SignatureMetadata(BaseModel):
    plan_id: str
    signer_name: str
    signer_role: str
    signer_device_id: str  # NEW: Track device
    signed_at: datetime
    plan_hash_at_signing: str  # NEW: Hash when signed
    signature_hash: str  # Hash of signature image (then delete image)
    
    def validate_against_plan(self, current_plan_hash: str) -> bool:
        """Verify plan hasn't changed since signing"""
        return self.plan_hash_at_signing == current_plan_hash
```

**Policy** (Add to `SECURITY.md`):
> **Signature Invalidation Policy**
>
> A signature becomes invalid if:
> 1. Plan data changes after signing (plan_hash mismatch)
> 2. Assessment data is modified post-signature
> 3. Device enrollment is revoked
>
> Action: Require re-signature before PDF export or EMR upload.

---

### 6. Keychain Accessibility Edge Case ‚ùå BLOCKING

**Problem**: Face ID changes can orphan SQLCipher keys if biometry is sole key derivation.

**Fix**: Wrapping key with proper Keychain accessibility classes.

**Implementation**:
```swift
// iOS Keychain configuration
let dbKeyWrapper = KeychainItem(
    service: "org.axxessphila.treatmentplan",
    account: "db-master-key",
    accessGroup: nil
)

// Key attributes
dbKeyWrapper.accessibility = .whenPasscodeSetThisDeviceOnly  // NOT biometry-dependent
dbKeyWrapper.useDataProtection = true

// Face ID is a gate, not the key
func unlockDatabase() async throws {
    // 1. Check Face ID
    try await authenticateWithBiometry()
    
    // 2. Retrieve wrapping key (available after passcode entry, not biometry)
    let wrapperKey = try await dbKeyWrapper.readKey()
    
    // 3. Derive SQLCipher key
    let dbKey = deriveKey(from: wrapperKey)
    
    // 4. Open database
    try openDatabase(with: dbKey)
}
```

**Update `SECURITY.md`**:
```markdown
## Keychain Storage Classes

| Item | Accessibility | Rationale |
|------|--------------|-----------|
| SQLCipher wrapping key | `kSecAttrAccessibleWhenPasscodeSetThisDeviceOnly` | Survives Face ID changes |
| OAuth refresh tokens | `kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly` | Available for background sync |
| Cached patient encryption keys | `kSecAttrAccessibleWhenUnlockedThisDeviceOnly` | Most restrictive |

**Face ID** is used as an access gate (unlock prompt), NOT as key derivation input. This prevents key loss on biometric enrollment changes.
```

---

### 7. TTL and Cache Scope Too Coarse ‚ùå BLOCKING

**Problem**: Flat 3-day cache policy doesn't match data volatility.

**Fix**: Resource-specific TTLs and enhanced purge policies.

**Updated Schema**:
```sql
-- src/sudplan/storage/migrations/001_initial_schema.sql
CREATE TABLE patients (
    mrn TEXT PRIMARY KEY,
    data JSON NOT NULL,
    emr_source TEXT NOT NULL,
    cached_at TIMESTAMP NOT NULL,
    expires_at TIMESTAMP NOT NULL,  -- 7 days for demographics
    resource_type TEXT DEFAULT 'demographics'
);

CREATE TABLE patient_vitals (
    id TEXT PRIMARY KEY,
    mrn TEXT NOT NULL,
    data JSON NOT NULL,
    cached_at TIMESTAMP NOT NULL,
    expires_at TIMESTAMP NOT NULL,  -- 12 hours for vitals
    FOREIGN KEY (mrn) REFERENCES patients(mrn)
);

CREATE TABLE patient_medications (
    id TEXT PRIMARY KEY,
    mrn TEXT NOT NULL,
    data JSON NOT NULL,
    cached_at TIMESTAMP NOT NULL,
    expires_at TIMESTAMP NOT NULL,  -- 24 hours for meds
    FOREIGN KEY (mrn) REFERENCES patients(mrn)
);

CREATE TABLE encounters (
    fin TEXT PRIMARY KEY,
    mrn TEXT NOT NULL,
    data JSON NOT NULL,
    cached_at TIMESTAMP NOT NULL,
    expires_at TIMESTAMP NOT NULL,  -- 72 hours for encounters
    FOREIGN KEY (mrn) REFERENCES patients(mrn)
);
```

**Cache Configuration** (`src/sudplan/config/cache.py`):
```python
from datetime import timedelta

CACHE_TTL = {
    'demographics': timedelta(days=7),
    'vitals': timedelta(hours=12),
    'medications': timedelta(hours=24),
    'encounters': timedelta(hours=72),
    'diagnoses': timedelta(days=3),
    'assessment_draft': timedelta(days=3),  # Or until uploaded
}

# Purge policy
PURGE_ON_FAILED_UNLOCKS = 5  # Device-wide purge after 5 failed attempts
```

---

### 8. FHIR Write Details Underspecified ‚ùå BLOCKING

**Problem**: "Write DocumentReference" documented but no schema, size limits, or error handling.

**Fix**: Complete FHIR templates and EMR integration guide.

**Create `docs/emr-integration.md`**:
```markdown
# EMR Integration Guide

## DocumentReference Template

```json
{
  "resourceType": "DocumentReference",
  "status": "current",
  "type": {
    "coding": [{
      "system": "http://loinc.org",
      "code": "11506-3",
      "display": "Hospital discharge plan"
    }]
  },
  "subject": {
    "reference": "Patient/{patientId}"
  },
  "context": {
    "encounter": [{
      "reference": "Encounter/{encounterId}"
    }]
  },
  "date": "{iso8601Timestamp}",
  "description": "Treatment Plan PDF",
  "content": [{
    "attachment": {
      "contentType": "application/pdf",
      "title": "TreatmentPlan_{opaqueUUID}.pdf",
      "hash": "{base64SHA256}",
      "size": {sizeInBytes},
      "data": "{base64EncodedPDF}"
    }
  }]
}
```

## Observation Template (Discrete Values)

```json
{
  "resourceType": "Observation",
  "status": "final",
  "code": {
    "coding": [{
      "system": "http://snomed.info/sct",
      "code": "225338004",
      "display": "Substance use assessment"
    }]
  },
  "subject": {
    "reference": "Patient/{patientId}"
  },
  "encounter": {
    "reference": "Encounter/{encounterId}"
  },
  "effectiveDateTime": "{iso8601}",
  "valueString": "{recommendedLevel}",  # "IOP", "PH", etc. - NOT ASAM labels
  "note": [{
    "text": "Neutral six-domain assessment completed"
  }]
}
```

## EMR Size Limits

| EMR | Attachment Size Limit | Chunking Required |
|-----|----------------------|-------------------|
| Cerner | 5 MB | If >5MB, compress or reject |
| EPIC | 10 MB | If >10MB, compress or reject |

## Error Handling

```python
async def upload_to_emr(pdf_bytes: bytes, metadata: dict) -> bool:
    size_mb = len(pdf_bytes) / (1024 * 1024)
    
    if size_mb > 5:  # Conservative limit
        raise ValueError(f"PDF too large: {size_mb:.1f}MB (max 5MB)")
    
    # Create DocumentReference
    doc_ref = create_document_reference(pdf_bytes, metadata)
    
    try:
        response = await fhir_client.create(doc_ref)
        return response.status_code == 201
    except Exception as e:
        await audit_log.log_error("emr_upload_failed", str(e))
        raise
```
```

---

### 9. Audit Log Needs Immutability ‚ùå BLOCKING

**Problem**: Encrypted log is good, but attacker with DB access can erase entries.

**Fix**: HMAC-chained append-only log with periodic anchors.

**Enhanced Schema**:
```sql
-- src/sudplan/storage/migrations/002_audit_hmac.sql
CREATE TABLE audit_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp TIMESTAMP NOT NULL,
    user_id TEXT,
    action TEXT NOT NULL,
    resource_type TEXT,
    resource_id TEXT,
    emr_operation TEXT,
    details JSON,
    ip_address TEXT,
    mac TEXT NOT NULL,  -- HMAC of this entry
    prev_mac TEXT       -- HMAC of previous entry (chain)
);

CREATE TABLE audit_checkpoints (
    checkpoint_id TEXT PRIMARY KEY,
    timestamp TIMESTAMP NOT NULL,
    last_audit_id INTEGER NOT NULL,
    checkpoint_mac TEXT NOT NULL,  -- Aggregate HMAC
    exported_at TIMESTAMP,
    export_destination TEXT,
    FOREIGN KEY (last_audit_id) REFERENCES audit_log(id)
);

CREATE INDEX idx_audit_log_mac ON audit_log(mac);
CREATE INDEX idx_audit_checkpoints_timestamp ON audit_checkpoints(timestamp);
```

**Implementation** (`src/sudplan/services/audit_service.py`):
```python
import hmac
import hashlib
from datetime import datetime, timedelta

class AuditService:
    def __init__(self, db: Database, secret_key: bytes):
        self.db = db
        self.secret_key = secret_key
        
    async def log(self, action: str, resource_type: str, resource_id: str, **kwargs):
        """Append audit entry with HMAC chain"""
        # Get previous MAC
        prev_entry = await self.db.query_one(
            "SELECT mac FROM audit_log ORDER BY id DESC LIMIT 1"
        )
        prev_mac = prev_entry['mac'] if prev_entry else "GENESIS"
        
        # Compute MAC
        entry_data = f"{datetime.utcnow().isoformat()}|{action}|{resource_type}|{resource_id}"
        mac = hmac.new(
            self.secret_key,
            f"{prev_mac}||{entry_data}".encode(),
            hashlib.sha256
        ).hexdigest()
        
        # Insert
        await self.db.execute(
            """INSERT INTO audit_log 
               (timestamp, action, resource_type, resource_id, details, mac, prev_mac)
               VALUES (?, ?, ?, ?, ?, ?, ?)""",
            (datetime.utcnow(), action, resource_type, resource_id, 
             json.dumps(kwargs), mac, prev_mac)
        )
        
        # Check if checkpoint needed (hourly)
        await self._maybe_checkpoint()
    
    async def _maybe_checkpoint(self):
        """Create hourly checkpoint"""
        last_checkpoint = await self.db.query_one(
            "SELECT timestamp FROM audit_checkpoints ORDER BY timestamp DESC LIMIT 1"
        )
        
        if not last_checkpoint or \
           (datetime.utcnow() - last_checkpoint['timestamp']) > timedelta(hours=1):
            await self._create_checkpoint()
    
    async def _create_checkpoint(self):
        """Create checkpoint with aggregate MAC"""
        last_entry = await self.db.query_one(
            "SELECT id, mac FROM audit_log ORDER BY id DESC LIMIT 1"
        )
        
        checkpoint_mac = hmac.new(
            self.secret_key,
            f"CHECKPOINT||{last_entry['id']}||{last_entry['mac']}".encode(),
            hashlib.sha256
        ).hexdigest()
        
        checkpoint_id = f"CHK-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
        
        await self.db.execute(
            """INSERT INTO audit_checkpoints 
               (checkpoint_id, timestamp, last_audit_id, checkpoint_mac)
               VALUES (?, ?, ?, ?)""",
            (checkpoint_id, datetime.utcnow(), last_entry['id'], checkpoint_mac)
        )
    
    async def export_daily_anchor(self) -> dict:
        """Export daily anchor for external verification"""
        checkpoint = await self.db.query_one(
            """SELECT * FROM audit_checkpoints 
               WHERE DATE(timestamp) = DATE('now', '-1 day')
               ORDER BY timestamp DESC LIMIT 1"""
        )
        
        return {
            'checkpoint_id': checkpoint['checkpoint_id'],
            'timestamp': checkpoint['timestamp'],
            'last_audit_id': checkpoint['last_audit_id'],
            'checkpoint_mac': checkpoint['checkpoint_mac']
        }
```

**Document in `docs/architecture.md`**:
> **Audit Log Immutability**
>
> - Each audit entry contains HMAC of previous entry (chain)
> - Hourly checkpoints aggregate chain state
> - Daily anchors exported to external store
> - Any tampering breaks chain and is detected on validation

---

### 10. CI Gate Should Be Hard Failing ‚ùå BLOCKING

**Problem**: Pre-commit hooks are bypassable. No CI enforcement.

**Fix**: GitHub Actions required checks.

**Already covered in Fix #3**, but add comprehensive workflow:

**`.github/workflows/ci.yml`**:
```yaml
name: CI Pipeline

on:
  pull_request:
  push:
    branches: [main, develop]

jobs:
  legal-check:
    name: Legal Compliance
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install tools
        run: sudo apt-get install -y poppler-utils
      - name: Run legal checker
        run: |
          chmod +x scripts/check-legal-compliance.sh
          ./scripts/check-legal-compliance.sh
  
  phi-check:
    name: PHI Filename Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Scan for MRN/FIN in filenames
        run: |
          if git diff --name-only origin/main | grep -Ei "(mrn|fin)"; then
            echo "‚ùå Found MRN/FIN in filename diff"
            exit 1
          fi
  
  tests:
    name: Test Suite
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: pip install -r requirements.txt -r requirements-dev.txt
      - name: Run tests
        run: pytest tests/ --cov=src/sudplan
```

**Repository Settings**:
1. Go to Settings ‚Üí Branches
2. Add branch protection rule for `main`
3. Require status checks to pass before merging:
   - ‚òë Legal Compliance
   - ‚òë PHI Filename Check
   - ‚òë Test Suite
4. ‚òë Require branches to be up to date before merging

---

### 11. SMART on FHIR Launch Details Underspecified ‚ùå BLOCKING

**Problem**: "OAuth 2.0" mentioned but no specifics on registration, PKCE, token storage, reauth.

**Fix**: Complete SMART on FHIR implementation guide.

**Add to `docs/emr-integration.md`**:
```markdown
## SMART on FHIR Launch

### Registration Model

**Static Registration** (Recommended for hospital deployment):
1. Register app with hospital IT during deployment
2. Receive `client_id` per tenant (Cerner, EPIC)
3. No dynamic registration required

**Configuration per Tenant**:
```json
{
  "cerner_prod": {
    "client_id": "xxxxx-xxxxx",
    "iss": "https://fhir-myrecord.cerner.com/r4/xxxxx",
    "redirect_uri": "treatmentplan://oauth/callback",
    "scopes": ["patient/Patient.read", "patient/Encounter.read", 
               "patient/Observation.write", "patient/DocumentReference.write"]
  },
  "epic_prod": {
    "client_id": "yyyyy-yyyyy",
    "iss": "https://fhir.epic.com/interconnect-fhir-oauth/api/FHIR/R4",
    "redirect_uri": "treatmentplan://oauth/callback",
    "scopes": ["patient/*.read", "patient/*.write"]
  }
}
```

### Authorization Flow

1. **EHR Launch** (preferred):
   ```
   EMR opens: treatmentplan://launch?iss={issuer}&launch={token}
   ```

2. **Authorization Request** (with PKCE):
   ```
   GET {iss}/oauth2/authorize?
       response_type=code&
       client_id={client_id}&
       redirect_uri={redirect_uri}&
       scope={scopes}&
       state={random_state}&
       aud={iss}&
       launch={launch_token}&
       code_challenge={sha256(verifier)}&
       code_challenge_method=S256
   ```

3. **Token Exchange**:
   ```
   POST {iss}/oauth2/token
   {
     "grant_type": "authorization_code",
     "code": "{auth_code}",
     "redirect_uri": "{redirect_uri}",
     "client_id": "{client_id}",
     "code_verifier": "{pkce_verifier}"
   }
   ```

4. **Token Storage**:
   - **Access Token**: Memory only (1 hour TTL)
   - **Refresh Token**: iOS Keychain `kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly`
   - **Rotation**: Refresh tokens rotated on each use (per EPIC/Cerner policy)

5. **Background Refresh**:
   ```python
   async def background_sync():
       # Only attempt if device unlocked
       if not await device_is_unlocked():
           return
       
       refresh_token = await keychain.get("oauth_refresh_token")
       new_tokens = await oauth_client.refresh(refresh_token)
       
       # Update keychain
       await keychain.set("oauth_refresh_token", new_tokens['refresh_token'])
   ```

### Token Expiry Handling

- Access tokens: 1 hour (refresh in background)
- Refresh tokens: 90 days (Cerner), 60 days (EPIC)
- On expiry: Prompt user to re-launch from EMR
- Never store passwords or long-lived credentials

### Security Constraints

- PKCE required (no client secret on mobile)
- Redirect URI must use custom scheme: `treatmentplan://`
- State parameter validated to prevent CSRF
- Tokens never logged or included in crash reports
```

---

### 12. Accessibility and i18n ‚ùå BLOCKING

**Problem**: Test data only has apostrophes. Missing accents, RTL, long strings.

**Fix**: Enhanced test data and PDF validation.

**Add to `data/test_patients.json`**:
```json
{
  "mrn": "TEST011234",
  "fin_current": "FIN2025110811",
  "demographics": {
    "first_name": "Jos√©",
    "last_name": "Garc√≠a-Rodr√≠guez",
    "dob": "1980-05-15",
    "gender": "Male",
    "preferred_language": "Spanish"
  },
  "notes": "Extended character test: √†√°√¢√£√§√•√®√©√™√´√¨√≠√Æ√Ø√≤√≥√¥√µ√∂√π√∫√ª√º"
},
{
  "mrn": "TEST012345",
  "fin_current": "FIN2025110812",
  "demographics": {
    "first_name": "ŸÖÿ≠ŸÖÿØ",  
    "last_name": "ÿßŸÑÿπŸÑŸä",
    "dob": "1975-03-20",
    "gender": "Male",
    "preferred_language": "Arabic"
  },
  "notes": "RTL test: Right-to-left text layout validation"
}
```

**PDF Test** (`tests/integration/test_pdf_i18n.py`):
```python
import pytest

@pytest.mark.parametrize("mrn,expected_chars", [
    ("TEST011234", "Garc√≠a-Rodr√≠guez"),
    ("TEST012345", "ŸÖÿ≠ŸÖÿØ ÿßŸÑÿπŸÑŸä"),
])
async def test_pdf_special_characters(mrn, expected_chars):
    """Verify PDF handles accents, RTL, and special characters"""
    patient = await get_patient_by_mrn(mrn)
    pdf_path = await export_plan(patient)
    
    # Extract text from PDF
    text = extract_pdf_text(pdf_path)
    
    # Verify characters rendered correctly
    assert expected_chars in text
```

---

## üìã Agent Handoff Note (Verbatim)

> **Agent Brief - Do Not Change**
>
> 1. Rename Python package `asamplan` to `sudplan` across repo, imports, tasks, and CI.
> 2. Replace all test tables and docs that show "2.1 - IOP" style strings with internal labels like `IOP` and move any mapping to `docs/mappings/levels.md`.
> 3. Upgrade `scripts/check-legal-compliance.sh` to scan whole repo, including docs and PDFs via `pdftotext`, and wire into GitHub Actions as a required check.
> 4. Add `docs/emr-integration.md` with DocumentReference and Observation templates and note attachment size limits per tenant.
> 5. Implement audit HMAC chaining with hourly checkpoint and daily anchor export.
> 6. Update `SECURITY.md` with Keychain classes and clarify Face ID is a gate, not the key.
> 7. Enforce resource-specific TTLs for cache and purge policies.
> 8. Add CI preflight for PDFs: flatten, embed fonts, optional PDF/A validation.
> 9. Refuse any commit that introduces "ASAM", "CONTINUUM", "CO Triage" to `src/`, `assets/forms`, or PDFs, unless the branch is `vendor-asam-licensed`.
> 10. Keep output filenames opaque. Never include MRN or FIN.

---

## ‚úÖ What Is Already Strong (Keep Intact)

- No PHI in filenames ‚úÖ
- Neutral app name ("Treatment Plan Assistant") ‚úÖ
- SMART on FHIR launch intent ‚úÖ
- Offline goal (8 hours) ‚úÖ
- Governance structure ‚úÖ
- Test data synthetic only ‚úÖ
- Constitution and legal framework ‚úÖ

**These are correct and consistent across all documents. Do not change.**

---

## üéØ Implementation Priority

**BLOCKING** (Must fix before Phase 1):
1. ‚úÖ **Package rename** (`asamplan` ‚Üí `sudplan`) ‚Äî **COMPLETED**
2. ‚úÖ **ASAM level label neutralization** ‚Äî **COMPLETED**
3. ‚úÖ **Enhanced legal checker + CI** ‚Äî **COMPLETED**
4. ‚úÖ **FHIR write templates** ‚Äî **COMPLETED**
5. ‚è≥ **Keychain accessibility classes** ‚Äî Needs iOS implementation
6. ‚è≥ **Audit HMAC chaining** ‚Äî Needs database implementation

**HIGH** (Week 1):
7. ‚è≥ **Resource-specific cache TTLs** ‚Äî Schema updates needed
8. ‚è≥ **PDF flattening and validation** ‚Äî PDFKit implementation needed
9. ‚úÖ **SMART on FHIR implementation guide** ‚Äî **COMPLETED**
10. ‚è≥ **i18n test data** ‚Äî Additional test patients needed

**MEDIUM** (Week 2):
11. ‚è≥ **Signature re-validation policy** ‚Äî Code implementation needed
12. ‚è≥ **CI preflight for PDFs** ‚Äî GitHub Actions workflow needed

---

## ‚úÖ Fixes Applied (November 8, 2025)

### 1. Package Renamed ‚úÖ COMPLETED
**What**: Renamed `asamplan` ‚Üí `sudplan` (Substance Use Disorder Plan)
**Where**: All documentation files (README.md, RESTRUCTURE_PLAN.md, IMPLEMENTATION_SUMMARY.md, DELIVERABLES_COMPLETE.md, DESIGN_CLARIFICATION.md)
**Impact**: Eliminates brand risk from internal code references
**Verified**: `grep -r "asamplan" .` returns only CRITICAL_FIXES.md (this file)

### 2. ASAM Level Labels Neutralized ‚úÖ COMPLETED
**What**: Replaced "2.1 - IOP" ‚Üí "IOP", "3.7 - Inpatient" ‚Üí "INP-MED", etc.
**Where**: 
- `data/README_TEST_PATIENTS.md` (patient summary table + level descriptions)
- `README.md` (test data table)
- Created `docs/mappings/levels.md` (private mapping table for analyst use only)

**New Internal Codes**:
- `EARLY` (Early Intervention)
- `OP` (Outpatient)
- `IOP` (Intensive Outpatient)
- `PH` (Partial Hospitalization)
- `RES-3` (Residential)
- `INP-MED` (Inpatient Medical)
- `INP-MED-PW` (Inpatient Pregnant Women)
- `INP-DETOX` (Medical Detoxification)
- `MAT-MAINT` (Medication Maintenance)

**Verified**: All tables now show neutral codes only

### 3. Enhanced Legal Compliance Checker ‚úÖ COMPLETED
**What**: Created production-grade legal scanner with comprehensive coverage
**Files Created**:
- `scripts/check-legal-compliance.sh` (145 lines, executable)
- `.github/workflows/legal-check.yml` (GitHub Actions required check)
- `.github/workflows/ci.yml` (Full CI pipeline with legal + PHI + tests)

**Scanner Features**:
- ‚úÖ Scans source code (`src/`) for prohibited terms
- ‚úÖ Scans documentation (docs, README, etc.) with context awareness
- ‚úÖ Extracts and scans PDF text content (requires `pdftotext`)
- ‚úÖ Detects MRN/FIN in filenames (PHI violation)
- ‚úÖ Detects ASAM PDF templates in `assets/`
- ‚úÖ Detects `asamplan` package naming
- ‚úÖ Returns exit code 1 on violations (blocks CI)

**Prohibited Terms Detected**:
- "ASAM Criteria"
- "ASAM Dimension"
- "ASAM Level"
- "ASAM Treatment Plan"
- "CONTINUUM"
- "CO-Triage" / "CO Triage"
- "The ASAM Criteria"

**CI Integration**: Legal check is **required status** before merge

### 4. FHIR Write Templates ‚úÖ COMPLETED
**What**: Created complete EMR integration guide with production templates
**File Created**: `docs/emr-integration.md` (500+ lines)

**Contents**:
- ‚úÖ SMART on FHIR launch flow (EHR-initiated with PKCE)
- ‚úÖ OAuth 2.0 token management (access, refresh, storage in Keychain)
- ‚úÖ Token refresh strategy for background sync
- ‚úÖ Data retrieval queries (Patient, Encounter, Condition, Medication, Observation)
- ‚úÖ **DocumentReference template** for PDF upload with size limits
- ‚úÖ **Observation template** for structured recommendations
- ‚úÖ Error handling and retry strategy
- ‚úÖ Cerner-specific configuration (5 MB limit, 90-day tokens)
- ‚úÖ EPIC-specific configuration (10 MB limit, 60-day tokens)
- ‚úÖ Security checklist

**Key Requirements Documented**:
- Use opaque UUIDs in filenames (NOT MRN/FIN)
- Include base64 SHA-256 hash of PDF
- Size limits: 5 MB (Cerner), 10 MB (EPIC)
- Use internal codes (`IOP`) NOT ASAM levels (`2.1`)

### 5. Private Mapping Table ‚úÖ COMPLETED
**What**: Created analyst-only reference for internal code meanings
**File Created**: `docs/mappings/levels.md` (150+ lines)

**Contents**:
- ‚ö†Ô∏è **CONFIDENTIAL - NOT TO BE SHIPPED**
- Internal code ‚Üí clinical description mapping
- ASAM reference column (if licensed)
- Severity score mapping (Domain 1-6)
- Proprietary algorithm notes (NOT ASAM's)
- Code usage examples (correct vs. incorrect)
- Future ASAM license integration plan

**Usage Restriction**: For analyst review and research ONLY. Must NOT appear in:
- User interface
- PDF exports
- EMR uploads
- API responses
- Log files

---

## ‚è≥ Fixes Pending Implementation

### 6. Keychain Accessibility Classes (iOS Code)
**Status**: Specification complete, needs Swift implementation
**Requirements**:
```swift
// DB wrapping key
kSecAttrAccessibleWhenPasscodeSetThisDeviceOnly  // Survives Face ID changes

// OAuth refresh tokens
kSecAttrAccessibleAfterFirstUnlockThisDeviceOnly  // Available for background sync

// Face ID is gate, not key derivation
// Use biometry for unlock prompt only
```

**Document in**: `SECURITY.md` (needs creation)

### 7. Resource-Specific Cache TTLs
**Status**: Schema design complete, needs SQL implementation
**Requirements**:
- Demographics: 7 days
- Vitals: 12 hours
- Medications: 24 hours
- Encounters: 72 hours
- Assessment drafts: 3 days or until uploaded
- Purge on 5 failed unlock attempts

**Update**: `src/sudplan/storage/migrations/001_initial_schema.sql`

### 8. Audit HMAC Chaining
**Status**: Algorithm documented, needs Python implementation
**Requirements**:
- Each entry contains HMAC of previous entry (chain)
- Hourly checkpoints with aggregate MAC
- Daily anchor export to external store
- Detect tampering via broken chain

**Schema**: Add `mac` and `prev_mac` columns to `audit_log` table
**Code**: `src/sudplan/services/audit_service.py`

### 9. PDF Flattening & Validation
**Status**: Requirements documented, needs Swift/Python implementation
**Requirements**:
- Flatten AcroForm after fill (pdftk or similar)
- Embed all fonts
- Validate file size (<5 MB for Cerner)
- Optional: PDF/A compliance check
- Optional: CMS digital signature

**Update**: `src/sudplan/services/pdf_service.py`

### 10. i18n Test Data
**Status**: Placeholders identified, needs JSON additions
**Requirements**:
- Add patient with accented characters (Jos√© Garc√≠a-Rodr√≠guez)
- Add patient with RTL name (Arabic: ŸÖÿ≠ŸÖÿØ ÿßŸÑÿπŸÑŸä)
- PDF validation tests for special characters

**Update**: `data/test_patients.json`

### 11. Signature Re-validation Policy
**Status**: Specification complete, needs code implementation
**Requirements**:
- Track `plan_hash_at_signing` in signature metadata
- Track `signer_device_id`
- Invalidate signature if plan data changes
- Require re-signature before export/upload

**Update**: `src/sudplan/models/signature.py`

### 12. CI PDF Preflight
**Status**: Requirements documented, needs workflow creation
**Requirements**:
- Generate test PDFs in CI
- Validate with qpdf/pdftk
- Check file size limits
- Optional: PDF/A validation

**Create**: `.github/workflows/pdf-validation.yml`

---

**Status**: üö® **5 CRITICAL FIXES COMPLETED, 7 PENDING**  
**Timeline**: Blocking items resolved, Week 1 items ready for implementation  
**Next**: Execute remaining fixes during Phase 1 implementation
